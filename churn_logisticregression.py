# -*- coding: utf-8 -*-
"""Churn-LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wmruw8t3YvXAv1di5DoHXwmvgG22pu5g
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score
from churn_data_cleaning import clean_data

def run_churn_LogReg():
    df = clean_data()
    #Encode target variable to binary (0 = No, 1 = Yes)
    df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})

    X = df.drop('Churn', axis=1)
    y = df['Churn']

    #Train/test split: 80% train, 20% test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    #Define categorical and numerical feature sets
    cat_cols = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
              'TechSupport', 'StreamingTV', 'StreamingMovies']
    num_cols = ['SeniorCitizen', 'tenure', 'TotalCharges', 'MonthlyCharges']

    #Apply scaling to numerical and one-hot encoding to categorical features
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])

    #Combine preprocessing and model into a single pipeline
    #defining the model and prepare the columns
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('logreg', LogisticRegression())
    ])

    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    # Evaluate model performance
    metrics = {
    "confusion_matrix": confusion_matrix(y_test, y_pred),
    # Proportion of predicted positives that are actually positive
    "precision": precision_score(y_test, y_pred),
    # Proportion of actual positives that were correctly identified
    "recall": recall_score(y_test, y_pred),
    # Harmonic mean of precision and recall
    "f1_score": f1_score(y_test, y_pred),
    # Area under the ROC curve
    "roc_auc": roc_auc_score(y_test, y_pred),
}

    return metrics