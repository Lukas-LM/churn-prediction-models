# -*- coding: utf-8 -*-
"""Churn-DecisionTree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O8l_k_tJzAnmVBTXXYruvOr0U3STorMz
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score
from churn_data_cleaning import clean_data

def run_churn_decisiontree():
    df = clean_data()
    #Encode target variable to binary (0 = No, 1 = Yes)
    df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})

    X = df.drop('Churn', axis=1)
    y = df['Churn']

    #Train/test split: 80% train, 20% test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    #Define categorical and numerical feature sets
    cat_cols = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
              'TechSupport', 'StreamingTV', 'StreamingMovies']
    num_cols = ['SeniorCitizen', 'tenure', 'TotalCharges', 'MonthlyCharges']

    #Apply one-hot encoding to categorical features
    preprocessor = ColumnTransformer([
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])
    #Combine preprocessing and model into a single pipeline
    #defining the model and prepare the columns
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('dectree', DecisionTreeClassifier(criterion= 'entropy', max_depth= 3))
    ])
    #Performs hyperparameter tuning by training the model with different
    #max_depth values and selects the best max_depth based on cross-validation
    #performance
    param_grid = {
        'dectree__max_depth' : [3, 5, 7, 9, 12, 15]
    }
    grid_search = GridSearchCV(estimator= pipeline, param_grid= param_grid, cv= 5, n_jobs= -1, verbose= 1)
    grid_search.fit(X_train, y_train)

    y_pred = grid_search.predict(X_test)

    # Evaluate model performance
    metrics = {
    "confusion_matrix": confusion_matrix(y_test, y_pred),
    # Proportion of predicted positives that are actually positive
    "precision": precision_score(y_test, y_pred),
    # Proportion of actual positives that were correctly identified
    "recall": recall_score(y_test, y_pred),
    # Harmonic mean of precision and recall
    "f1_score": f1_score(y_test, y_pred),
    # Area under the ROC curve
    "roc_auc": roc_auc_score(y_test, y_pred),
    }
    return metrics
