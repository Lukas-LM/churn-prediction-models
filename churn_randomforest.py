# -*- coding: utf-8 -*-
"""Churn-RandomForest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EXpUP-ejDZ4ReKmnhU_axSCK4qa98X5M
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score
from churn_data_cleaning import clean_data

def run_churn_RandomForest():
    df = clean_data()
    #Encode target variable to binary (0 = No, 1 = Yes)
    df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})

    df.drop('customerID', axis=1)

    X = df.drop('Churn', axis=1)
    y = df['Churn']

    #Train/test split: 80% train, 20% test
    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)

    #Define categorical and numerical feature sets
    cat_cols = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
              'TechSupport', 'StreamingTV', 'StreamingMovies','gender', 'Partner', 'Dependents', 'PhoneService',
             'PaymentMethod', 'PaperlessBilling', 'Contract', 'InternetService']
    num_cols = ['SeniorCitizen', 'tenure', 'TotalCharges', 'MonthlyCharges']

    #Apply one-hot encoding to categorical features
    preprocessor = ColumnTransformer([
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])
    #Combine preprocessing and model into a single pipeline
    #defining the model and prepare the columns
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('rf', RandomForestClassifier(class_weight= 'balanced', n_estimators=25, max_depth= None, random_state=42))
    ])

    #Performs hyperparameter tuning by training the model with different
    #n_estimators values and selects the best n_estimators based on cross-validation
    #performance
    #after multiple stages of parameter tuning n_estimators= 270 deliver the best performance
    param_grid = {
        'rf__n_estimators' : [25,50,75,100,150,200,300,400],
        'rf__max_depth' : [3, 5, 7, 9, 12, 15, None]
    }
    grid_search = GridSearchCV(estimator= pipeline, param_grid= param_grid, cv= 5, n_jobs= -1, verbose= 1)
    grid_search.fit(X_train, y_train)

    y_pred = grid_search.predict(X_test)

    # Evaluate model performance
    metrics = {
    "confusion_matrix": confusion_matrix(y_test, y_pred),
    # Proportion of predicted positives that are actually positive
    "precision": precision_score(y_test, y_pred),
    # Proportion of actual positives that were correctly identified
    "recall": recall_score(y_test, y_pred),
    # Harmonic mean of precision and recall
    "f1_score": f1_score(y_test, y_pred),
    # Area under the ROC curve
    "roc_auc": roc_auc_score(y_test, y_pred),
    }
    return metrics
